{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ad5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620665e",
   "metadata": {},
   "source": [
    "### ADD % NREM DURING SLEEP PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0bd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_parquet('metrics/light_metrics.parquet', engine='pyarrow')\n",
    "print(data_df['room'].unique(),len(sorted(data_df['participant_id'].unique())))\n",
    "\n",
    "data_df = data_df.rename(columns={'tib_mean_light':'ntib_mean_light', \n",
    "                'tib_geometric_mean_light':'ntib_geometric_mean_light', 'before_tib_mean_light':'before_ntib_mean_light',\n",
    "       'before_tib_geometric_mean_light':'before_ntib_geometric_mean_light', 'after_tib_mean_light':'after_ntib_mean_light',\n",
    "       'after_tib_geometric_mean_light':'after_ntib_geometric_mean_light'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bef66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "light = data_df[data_df['room']=='Lounge']\n",
    "\n",
    "light.columns = [col_name+'_lounge'if col_name not in ['participant_id', 'room', 'date', 'tib_cluster_number', 'daily_start',\n",
    "       'metereological_season'] else col_name for col_name in light.columns]\n",
    "light = light.drop(columns=['room','daily_start','metereological_season','tib_cluster_number'])\n",
    "\n",
    "for i in['Bedroom','Kitchen','Hallway','Bathroom']:\n",
    "    light_i = data_df[data_df['room']==i][['participant_id', 'date',  'mean_daily_light',\n",
    "           'geometric_mean_daily_light', 'half_light', 'time_half_light',\n",
    "           'half_loglight', 'time_half_loglight', 'hours_below_10', 'hours_10-100',\n",
    "           'hours_100-500', 'hours_over_500', 'hours_over_1000', \n",
    "           'ntib_mean_light', 'ntib_geometric_mean_light',\n",
    "           'before_ntib_mean_light', 'before_ntib_geometric_mean_light',\n",
    "           'after_ntib_mean_light', 'after_ntib_geometric_mean_light']]\n",
    "\n",
    "    light_i.columns = [col_name+'_'+i if col_name not in ['participant_id', 'room', 'date', 'tib_cluster_number', 'daily_start',\n",
    "           'metereological_season',] else col_name for col_name in light_i.columns]\n",
    "    \n",
    "    light_i.columns = [x.lower() for x in light_i.columns]\n",
    "\n",
    "\n",
    "    light = light.merge(light_i, on=['participant_id','date'],how='outer')\n",
    "print(len(light), len(light['participant_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4f28ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "light.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbdb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_parquet('metrics/temperature_metrics_bedroom_using_cluster.parquet', engine='pyarrow')\n",
    "temp = temp.drop(columns=['metereological_season','daily_start','tib_cluster_number'])\n",
    "temp = temp.rename(columns={'tib_mean_temperature':'ntib_mean_temperature',\n",
    "       'before_tib_mean_temperature':'before_ntib_mean_temperature',\n",
    "       'after_tib_mean_temperature':'after_ntib_mean_temperature'})\n",
    "\n",
    "print(len(temp),temp['room'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fe070",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = temp[temp['room']=='Lounge']\n",
    "temperature['amplitude_temperature_lounge'] = temperature['max_daily_temperature']-temperature['min_daily_temperature']\n",
    "temperature.columns = [col_name+'_lounge'if col_name not in ['participant_id', 'room', 'date','amplitude_temperature_lounge'] else col_name\n",
    "                       for col_name in temperature.columns]\n",
    "temperature = temperature.drop(columns=['room'])\n",
    "\n",
    "\n",
    "for i in ['Bedroom','Kitchen','Hallway','Bathroom']:\n",
    "    temperature_i = temp[temp['room']==i][['participant_id', 'room', 'date', 'mean_daily_temperature',\n",
    "       'max_daily_temperature', 'min_daily_temperature','time_max_daily_temperature', 'time_min_daily_temperature',\n",
    "       'ntib_mean_temperature', 'before_ntib_mean_temperature','after_ntib_mean_temperature']]\n",
    "    temperature_i['amplitude_temperature_'+i] = temperature_i['max_daily_temperature']-temperature_i['min_daily_temperature']\n",
    "\n",
    "    temperature_i.columns = [col_name+'_'+i if col_name not in ['participant_id', 'room', 'date','amplitude_temperature_'+i] \n",
    "                             else col_name for col_name in temperature_i.columns]\n",
    "    \n",
    "    temperature_i = temperature_i.drop(columns=['room'])\n",
    "    \n",
    "    temperature_i.columns = [x.lower() for x in temperature_i.columns]\n",
    "\n",
    "\n",
    "    temperature = temperature.merge(temperature_i, on=['participant_id','date'],how='outer')\n",
    "print(len(temperature), len(temperature['participant_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df = pd.read_parquet('metrics/in_bed_metrics_using_cluster.parquet', engine='pyarrow')\n",
    "sleep_df = sleep_df.rename(columns={'time_in_bed_duration':'nocturnal_time_in_bed_duration', 'time_in_bed_period':'nocturnal_time_in_bed_period'})\n",
    "\n",
    "sleep_df['median_sleep_bouts'] = sleep_df['sleep_bouts'].apply(lambda x: np.median(x))\n",
    "sleep_df['number_of_sleep_bouts'] = sleep_df['sleep_bouts'].apply(lambda x: len(x))\n",
    "\n",
    "sleep_df['median_duration_of_bed_exits'] = sleep_df['out_bed_bouts'].apply(lambda x: np.median(x))\n",
    "sleep_df['number_of_bed_exits'] = sleep_df['out_bed_bouts'].apply(lambda x: len(x))\n",
    "\n",
    "sleep_df['bed_exit_rate'] =  sleep_df['number_of_bed_exits']/sleep_df['nocturnal_time_in_bed_period']\n",
    "print(len(sleep_df),len(sleep_df['participant_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfed283",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df['median_wake_bouts'] = sleep_df['wake_bouts'].apply(lambda x: np.median(x))\n",
    "sleep_df['number_of_wake_bouts'] = sleep_df['wake_bouts'].apply(lambda x: len(x))\n",
    "sleep_df['sleep_efficiency'] = 100* (sleep_df['sleep_duration']/sleep_df['nocturnal_time_in_bed_period'])\n",
    "sleep_df['nrem_sleep_perc'] = 100* (sleep_df['withings_nrem_sleep_duration']/sleep_df['sleep_period'])\n",
    "sleep_df[['median_wake_bouts','number_of_wake_bouts','sleep_efficiency','nrem_sleep_perc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ff4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_df['midpoint_sleep_numeric'] = sleep_df['midpoint_sleep'].dt.hour + (sleep_df['midpoint_sleep'].dt.minute/60)\n",
    "sleep_df['midpoint_sleep_numeric'] = sleep_df['midpoint_sleep_numeric'].apply(lambda x: x-24 if x>18 else x)\n",
    "sleep_df['tib_onset_numeric'] = sleep_df['tib_onset'].dt.hour + (sleep_df['tib_onset'].dt.minute/60)\n",
    "sleep_df['ntib_onset_numeric'] = sleep_df['tib_onset_numeric'].apply(lambda x: x-24 if x>18 else x)\n",
    "sleep_df['tib_offset_numeric'] = sleep_df['tib_offset'].dt.hour + (sleep_df['tib_offset'].dt.minute/60)\n",
    "sleep_df['ntib_offset_numeric'] = sleep_df['tib_offset_numeric'].apply(lambda x: x-24 if x>18 else x)\n",
    "sleep_df['sleep_onset_numeric'] = sleep_df['sleep_onset'].dt.hour + (sleep_df['sleep_onset'].dt.minute/60)\n",
    "sleep_df['sleep_onset_numeric'] = sleep_df['sleep_onset_numeric'].apply(lambda x: x-24 if x>18 else x)\n",
    "sleep_df['sleep_offset_numeric'] = sleep_df['sleep_offset'].dt.hour + (sleep_df['sleep_offset'].dt.minute/60)\n",
    "sleep_df['sleep_offset_numeric'] = sleep_df['sleep_offset_numeric'].apply(lambda x: x-24 if x>18 else x)\n",
    "\n",
    "sleep_ids = sleep_df['participant_id'].unique()\n",
    "\n",
    "sleep_df = sleep_df.drop(columns=['check_percs','tib_onset_numeric','tib_offset_numeric'])\n",
    "print(len(sleep_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('participants with sleep and bedroom  light ',len(light['participant_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5af1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df = sleep_df.merge(temperature, on=['participant_id','date'],how='outer')\n",
    "print('participants with sleep and bedroom temperature ', len(whole_df['participant_id'].unique()))\n",
    "whole_df = whole_df.merge(light, on=['participant_id','date'],how='outer')\n",
    "print('participants with sleep and bedroom temperature and light ',len( whole_df['participant_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968467e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "naps = pd.read_parquet('metrics/naps_metrics_using_cluster_22_JAN_2024.parquet', engine='pyarrow')\n",
    "short_ntibs = pd.read_parquet('metrics/short_ntibs_metrics_using_cluster_22_JAN_2024.parquet', engine='pyarrow')\n",
    "print(len(whole_df.columns))\n",
    "\n",
    "whole_df = whole_df.merge(naps, on=['participant_id','date'],how='outer')\n",
    "print(len(whole_df.columns))\n",
    "\n",
    "whole_df = whole_df.merge(short_ntibs, on=['participant_id','date'],how='outer')\n",
    "print(len(whole_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37818d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df.columns = [c.replace(' ','_').replace('-','_').replace(')','').replace('(','') for c in whole_df]\n",
    "\n",
    "whole_df['temperature_category'] = pd.cut(whole_df['ntib_mean_temperature_bedroom'],3, labels=[\"cold\", \"medium\", \"hot\"])\n",
    "print(len(whole_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df[whole_df.isnull().any(axis=1)]\n",
    "\n",
    "whole_df.columns[whole_df.isna().any()].tolist()\n",
    "whole_df.columns[whole_df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df.columns = [c.replace(' ','_').replace('-','_').replace(')','').replace('(','') for c in whole_df]\n",
    "whole_df.columns = [x.lower() for x in whole_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_dates = whole_df.groupby('participant_id')['date'].min()\n",
    "initial_dates = initial_dates.to_frame().rename(columns={'date':'min_date'}).reset_index()\n",
    "whole_df = whole_df.merge(initial_dates, on=['participant_id'],how='left')\n",
    "whole_df['time_in_study'] = (whole_df['date'] - whole_df['min_date']).dt.days\n",
    "\n",
    "whole_df.rename(columns={'withings_wake_state_during_sleep_period':'w_wake_st_dur_sleep_period',\n",
    "                   'withings_nulls_during_sleep_period':'w_nulls_dur_sleep_period',\n",
    "                   'withings_nulls_during_sleep_period_percentage': 'w_nulls_dur_sleep_period_perc'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3210e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df['month'] = pd.to_datetime(whole_df['date']).dt.strftime('%B')#.month\n",
    "\n",
    "whole_df['bimonth'] ='JanFeb'\n",
    "whole_df.loc[(whole_df['month']=='March')|(whole_df['month']=='April'), 'bimonth'] = 'MarApr'\n",
    "whole_df.loc[(whole_df['month']=='May')|(whole_df['month']=='June'), 'bimonth'] = 'MayJun'\n",
    "whole_df.loc[(whole_df['month']=='July')|(whole_df['month']=='August'), 'bimonth'] = 'JulAug'\n",
    "whole_df.loc[(whole_df['month']=='September')|(whole_df['month']=='October'), 'bimonth'] = 'SepOct'\n",
    "whole_df.loc[(whole_df['month']=='November')|(whole_df['month']=='December'), 'bimonth'] = 'NovDec'\n",
    "whole_df.groupby('bimonth')['month'].apply(lambda x: list(np.unique(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7933128",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df[['date','bimonth']].groupby('bimonth').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df[['date','month']].groupby('month').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_metereological(date):\n",
    "    year = str(date.year)\n",
    "    seasons = {'around-spring-equinox': pd.date_range(start=year+'-02-04', end=year+'-05-05', tz='UTC'),\n",
    "               'around-summer-solstice': pd.date_range(start=year+'-05-06', end=year+'-08-06', tz='UTC'),\n",
    "               'around-autumn-equinox': pd.date_range(start=year+'-08-07', end=year+'-11-07', tz='UTC')}\n",
    "    if date in seasons['around-spring-equinox']:\n",
    "        return 'around-spring-equinox'\n",
    "    if date in seasons['around-summer-solstice']:\n",
    "        return 'around-summer-solstice'\n",
    "    if date in seasons['around-autumn-equinox']:\n",
    "        return 'around-autumn-equinox'\n",
    "    else:\n",
    "        return 'around-winter-solstice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df['metereological_season'] = whole_df['date'].apply(lambda x: season_metereological(pd.to_datetime(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df[['date','metereological_season']].groupby(['metereological_season']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9d4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f7e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df.to_csv('master_06_FEB_2024.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b53dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "##FINAL PROCESS TO SAVE file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_df.columns[whole_df.isna().any()].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
